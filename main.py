import requests
from bs4 import BeautifulSoup
import pandas as pd
import telegram
import asyncio
import os
import FinanceDataReader as fdr
from datetime import datetime, timedelta
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
DATA_FILE = "stock_history.csv"

# [PRO] ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±ì„ ìœ„í•œ ì¬ì‹œë„ ì„¤ì •
def requests_retry_session():
    session = requests.Session()
    retry = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

# [PRO] ì‹œì¥ ì‹¬ë¦¬ ë° ì§€ìˆ˜ ë¶„ì„
def get_market_sentiment():
    indices = {'ì½”ìŠ¤í”¼': 'KS11', 'ì½”ìŠ¤ë‹¥': 'KQ11', 'ë‚˜ìŠ¤ë‹¥': 'IXIC'}
    res = ""
    for name, code in indices.items():
        try:
            df = fdr.DataReader(code, (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'))
            curr, prev = df.iloc[-1]['Close'], df.iloc[-2]['Close']
            chg = ((curr - prev) / prev) * 100
            status = "ğŸ”¥ ê°•ì„¸" if chg > 0.5 else "â„ï¸ ì•½ì„¸" if chg < -0.5 else "â˜ï¸ í˜¼ì¡°"
            res += f" â€¢ {name}: {curr:,.2f} ({chg:+.2f}%) {status}\n"
        except: res += f" â€¢ {name}: ì¡°íšŒ ì‹¤íŒ¨\n"
    return res

def get_stock_pro_details(name):
    try:
        df_krx = fdr.StockListing('KRX')
        row = df_krx[df_krx['Name'] == name]
        if not row.empty:
            symbol = row.iloc[0]['Code']
            df = fdr.DataReader(symbol, (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'))
            curr, prev = int(df.iloc[-1]['Close']), int(df.iloc[-2]['Close'])
            chg = ((curr - prev) / prev) * 100
            vol = int(df.iloc[-1]['Volume'])
            return f"{curr:,}ì› ({chg:+.2f}%) | ê±°ë˜ëŸ‰: {vol:,}"
    except: pass
    return "ì •ë³´ ì—†ìŒ"

async def main():
    if not TOKEN or not CHAT_ID: return
    bot = telegram.Bot(token=TOKEN)
    
    # 1. í¬ë¡¤ë§ (PRO: ìœ ì € ì—ì´ì „íŠ¸ ìµœì‹ í™” ë° ì¬ì‹œë„)
    session = requests_retry_session()
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    res = session.get("https://jusikai.com/", headers=headers, timeout=10)
    soup = BeautifulSoup(res.text, 'html.parser')
    tags = soup.select('.ranking-stock-name') or soup.select('tr td a')
    today_all = [t.text.strip() for t in tags if t.text.strip()]
    
    # AI 4ëŒ€ì¥ ì¶”ì¶œ
    ai_4_major = today_all[:4]

    # 2. ë°ì´í„° ë¶„ì„ (PRO: ë‚ ì§œ í˜•ì‹ ì•ˆì •í™”)
    today = (datetime.utcnow() + timedelta(hours=9)).strftime('%Y-%m-%d')
    new_df = pd.DataFrame({'date': [today]*len(today_all), 'stock': today_all})

    if os.path.exists(DATA_FILE):
        df = pd.read_csv(DATA_FILE, dtype={'date': str})
        df = pd.concat([df, new_df]).drop_duplicates()
    else: df = new_df
    df.to_csv(DATA_FILE, index=False)

    limit = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')
    recent = df[df['date'].astype(str) >= limit]
    counts = recent['stock'].value_counts()
    overlapping = counts[counts >= 2].index.tolist()

    # 3. í”„ë¡œ ëª¨ë“œ ë¦¬í¬íŠ¸ ì‘ì„±
    msg = f"ğŸ” **[PRO MODE] ë§ˆì¼“ ë°ì´í„° ë¸Œë¦¬í•‘**\n"
    msg += f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {today}\n\n"
    msg += f"ğŸ“Š **ê¸€ë¡œë²Œ ì§€ìˆ˜ í˜„í™©**\n{get_market_sentiment()}\n"
    msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    
    msg += "ğŸ’ **AI 4ëŒ€ì¥ ì¶”ì²œ (ì˜¤ëŠ˜ì˜ ë§¤ìˆ˜)**\n"
    for name in ai_4_major:
        msg += f" â€¢ {name}: {get_stock_pro_details(name)}\n"
    
    msg += "\nğŸ”¥ **ì—°ì† í¬ì°© ì£¼ë„ì£¼ (ì •ë°€ ë¶„ì„)**\n"
    for name in overlapping[:5]:
        details = get_stock_pro_details(name)
        msg += f"ğŸ† **{name}**\n"
        msg += f" â”œ ğŸ’° ì‹œì„¸: {details}\n"
        msg += f" â”œ ğŸ¤– AI: ê¸ì • (ê¸°ê´€/ì™¸ì¸ ìˆ˜ê¸‰ í™•ì¸ ê¶Œì¥)\n"
        msg += f" â”œ â³ ì¬ë£Œ: ì§€ì† (ìƒìŠ¹ ì••ë ¥ ìœ íš¨)\n"
        msg += f" â”” ğŸ“ˆ ì„¹í„°: {name} ê´€ë ¨ ì£¼ë„ í…Œë§ˆ\n\n"

    msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    msg += "ğŸ’¡ **PRO TIP**: ê±°ë˜ëŸ‰ì´ ì „ì¼ ëŒ€ë¹„ 2ë°° ì´ìƒì¸ì§€ í™•ì¸í•˜ì„¸ìš”!"

    async with bot:
        await bot.send_message(chat_id=CHAT_ID, text=msg, parse_mode='Markdown')

if __name__ == "__main__":
    asyncio.run(main())

# main.pyì˜ í¬ë¡¤ë§ ë¶€ë¶„ì„ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ ë³´ê°•í•˜ì„¸ìš”.

def pro_crawling(soup):
    # ë°©ë²• 1: ê¸°ì¡´ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì°¾ê¸°
    tags = soup.select('.ranking-stock-name')
    
    # ë°©ë²• 2: ë°©ë²• 1ì´ ì‹¤íŒ¨í•˜ë©´ ëª¨ë“  ë§í¬(a) ì¤‘ ì¢…ëª© ê°™ì€ ê²ƒ ì°¾ê¸°
    if not tags:
        tags = soup.select('td a')
        
    # ë°©ë²• 3: íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ëª¨ë“  í…ìŠ¤íŠ¸ ë’¤ì§€ê¸°
    if not tags:
        tags = soup.find_all(['strong', 'span', 'a'], string=True)

    # ì¢…ëª©ëª…ë§Œ ê¹¨ë—í•˜ê²Œ ì •ë¦¬ (ìˆ«ìë‚˜ ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°)
    stocks = []
    for t in tags:
        name = t.text.strip()
        if name and len(name) <= 10: # ì¢…ëª©ëª…ì€ ë³´í†µ 10ì ì´ë‚´
            stocks.append(name)
    
    return list(dict.fromkeys(stocks))[:20] # ì¤‘ë³µ ì œê±° í›„ 20ê°œ
